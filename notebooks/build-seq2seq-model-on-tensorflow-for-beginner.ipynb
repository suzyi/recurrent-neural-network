{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple dynamic seq2seq with TensorFlow\n",
    "Guorui Shen, guorui233@outlook.com\n",
    "\n",
    "Tutorial for beginer to start building a seq2seq model. Modified from https://github.com/ematvey/tensorflow-seq2seq-tutorials\n",
    "\n",
    "**Task description**. Given a input, which is a list of integer numbers, say $a = [3, 7, 2]$, the encoder decoder seq2seq model is trained to remember and return the list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import helpers\n",
    "\n",
    "tf.reset_default_graph()\n",
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "PAD = 0\n",
    "EOS = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model inputs and outputs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_inputs = tf.placeholder(shape=(None, None), dtype=tf.int32, name='encoder_inputs')   # (8, 100)\n",
    "decoder_targets = tf.placeholder(shape=(None, None), dtype=tf.int32, name='decoder_targets') # (9, 100)\n",
    "decoder_inputs = tf.placeholder(shape=(None, None), dtype=tf.int32, name='decoder_inputs')   # (9, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = tf.Variable(tf.random_uniform([10, 20], -1.0, 1.0), dtype=tf.float32)# (10, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"embedding_lookup:0\", shape=(?, ?, 20), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# (10, 8, 20)\n",
    "encoder_inputs_embedded = tf.nn.embedding_lookup(embeddings, encoder_inputs)\n",
    "\n",
    "# (10, 9, 20)\n",
    "decoder_inputs_embedded = tf.nn.embedding_lookup(embeddings, decoder_inputs)\n",
    "print encoder_inputs_embedded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # deletable\n",
    "# encoder_in = [[5, 5, 4, 0, 0, 0, 0, 0], [3, 5, 3, 9, 3, 8, 9, 0]]\n",
    "# print(sess.run(embeddings).shape)\n",
    "# print(sess.run(tf.nn.embedding_lookup(embeddings, encoder_in)).shape)\n",
    "# print(sess.run(tf.nn.embedding_lookup(embeddings, encoder_in))[:, :, :5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_cell = tf.contrib.rnn.LSTMCell(20)\n",
    "\n",
    "# 'encoder_final_state' is a tensor of shape [batch_size, num_hidden]\n",
    "# 'encoder_outputs' is a tensor of shape [batch_size, max_unrolling_time, num_hidden]\n",
    "encoder_outputs, encoder_final_state = tf.nn.dynamic_rnn(\n",
    "    encoder_cell, encoder_inputs_embedded,# (100, 8, 20), max_unrolling_time=8, num_hidden=20\n",
    "    dtype=tf.float32, time_major=True,\n",
    ")\n",
    "\n",
    "del encoder_outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_cell = tf.contrib.rnn.LSTMCell(20)\n",
    "\n",
    "# 'decoder_outputs' is a tensor of shape [batch_size, max_unrolling_time, num_hidden]\n",
    "decoder_outputs, decoder_final_state = tf.nn.dynamic_rnn(\n",
    "    decoder_cell, decoder_inputs_embedded,\n",
    "\n",
    "    initial_state=encoder_final_state,\n",
    "\n",
    "    dtype=tf.float32, time_major=True, scope=\"plain_decoder\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'decoder_logits' is a tensor of shape [batch_size, max_unrolling_time, num_outputs]\n",
    "decoder_logits = tf.contrib.layers.fully_connected(decoder_outputs, num_outputs=10, activation_fn=None)\n",
    "\n",
    "# returns the index with the largest value across axes of a tensor.\n",
    "# 'decoder_prediction' is a tensor of shape [batch_size, max_unrolling_time, 1]\n",
    "decoder_prediction = tf.argmax(decoder_logits, axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4611502\n"
     ]
    }
   ],
   "source": [
    "# deletable\n",
    "a1, a2 = 6, 5\n",
    "b1, b2 = tf.one_hot(a1, depth=10), tf.one_hot(a2, depth=10)\n",
    "print(sess.run(tf.nn.softmax_cross_entropy_with_logits(labels=b1, logits=b2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-11-06a6062bba14>:3: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See tf.nn.softmax_cross_entropy_with_logits_v2.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 'stepwise_cross_entropy' is a tensor of shape [batch_size, max_unrolling_time, 1]\n",
    "stepwise_cross_entropy = tf.nn.softmax_cross_entropy_with_logits(\n",
    "    labels=tf.one_hot(decoder_targets, depth=10, dtype=tf.float32),\n",
    "    logits=decoder_logits,\n",
    ")\n",
    "\n",
    "loss = tf.reduce_mean(stepwise_cross_entropy)\n",
    "train_op = tf.train.AdamOptimizer().minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_encoded:\n",
      "[[6 3 9]\n",
      " [0 4 8]\n",
      " [0 0 7]]\n",
      "decoder inputs:\n",
      "[[1 1 1]\n",
      " [0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]]\n",
      "decoder predictions:\n",
      "[[9 9 0]\n",
      " [9 9 4]\n",
      " [4 4 4]\n",
      " [4 4 4]]\n"
     ]
    }
   ],
   "source": [
    "batch_ = [[6], [3, 4], [9, 8, 7]]\n",
    "\n",
    "batch_, batch_length_ = helpers.batch(batch_)\n",
    "print('batch_encoded:\\n' + str(batch_))\n",
    "\n",
    "din_, dlen_ = helpers.batch(np.ones(shape=(3, 1), dtype=np.int32),\n",
    "                            max_sequence_length=4)\n",
    "print('decoder inputs:\\n' + str(din_))\n",
    "\n",
    "pred_ = sess.run(decoder_prediction,\n",
    "    feed_dict={\n",
    "        encoder_inputs: batch_,\n",
    "        decoder_inputs: din_,\n",
    "    })\n",
    "print('decoder predictions:\\n' + str(pred_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "head of the batch:\n",
      "[2, 2, 2, 2, 2, 2, 3]\n",
      "[3, 2, 2, 3, 2, 2, 2, 3]\n",
      "[3, 3, 3, 3, 3, 3, 2, 3]\n",
      "[3, 2, 2]\n",
      "[2, 2, 3, 3, 2, 2]\n",
      "[3, 2, 3, 3, 2, 2, 3, 3]\n",
      "[3, 2, 3, 3, 2, 3]\n",
      "[2, 2, 2, 2]\n",
      "[3, 2, 3, 2, 2]\n",
      "[3, 3, 3, 2, 2, 3, 2, 3]\n",
      "[2, 2, 3, 2, 2, 2, 2, 3]\n",
      "[2, 2, 3, 2, 2, 3, 3, 2]\n",
      "[3, 2, 2, 3, 2, 2]\n",
      "[3, 2, 3, 3, 3, 3, 2]\n",
      "[3, 3, 2, 3, 2, 3, 3]\n"
     ]
    }
   ],
   "source": [
    "batch_size = 100\n",
    "\n",
    "batches = helpers.random_sequences(length_from=3, length_to=8, # each list has length of at least 3, at most 8\n",
    "                                   vocab_lower=2, vocab_upper=10, # no less than 2, strictly less than 10\n",
    "                                   batch_size=batch_size)\n",
    "\n",
    "print('head of the batch:')\n",
    "for seq in next(batches)[:10]:\n",
    "    print(seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def next_feed():\n",
    "    batch = next(batches)\n",
    "    encoder_inputs_, _ = helpers.batch(batch)\n",
    "    decoder_targets_, _ = helpers.batch(\n",
    "        [(sequence) + [EOS] for sequence in batch]\n",
    "    )\n",
    "    decoder_inputs_, _ = helpers.batch(\n",
    "        [[EOS] + (sequence) for sequence in batch]\n",
    "    )\n",
    "    return {\n",
    "        encoder_inputs: encoder_inputs_,\n",
    "        decoder_inputs: decoder_inputs_,\n",
    "        decoder_targets: decoder_targets_,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 100)\n",
      "(9, 100)\n",
      "-----------------------------------------------------------------\n",
      "0th encoder_input  is [3 3 3 0 0 0 0 0]\n",
      "0th decoder_input  is [1 3 3 3 0 0 0 0 0]\n",
      "0th decoder_target is [3 3 3 1 0 0 0 0 0]\n",
      "-----------------------------------------------------------------\n",
      "1th encoder_input  is [3 3 3 0 0 0 0 0]\n",
      "1th decoder_input  is [1 3 3 3 0 0 0 0 0]\n",
      "1th decoder_target is [3 3 3 1 0 0 0 0 0]\n",
      "-----------------------------------------------------------------\n",
      "2th encoder_input  is [3 2 3 3 3 2 0 0]\n",
      "2th decoder_input  is [1 3 2 3 3 3 2 0 0]\n",
      "2th decoder_target is [3 2 3 3 3 2 1 0 0]\n"
     ]
    }
   ],
   "source": [
    "data = next_feed()\n",
    "print(data[encoder_inputs].shape)\n",
    "print(data[decoder_targets].shape)\n",
    "for i in range(2):\n",
    "    print('-----------------------------------------------------------------')\n",
    "    print('{}th encoder_input  is {}'.format(i, data[encoder_inputs][:, i]))\n",
    "    print('{}th decoder_input  is {}'.format(i, data[decoder_inputs][:, i]))\n",
    "    print('{}th decoder_target is {}'.format(i, data[decoder_targets][:, i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_track = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0th batch\n",
      "  minibatch loss: 2.38414382935\n",
      "  sample 1:\n",
      "    input     > [3 3 3 3 0 0 0 0]\n",
      "    predicted > [9 9 2 2 2 4 4 4 4]\n",
      "  sample 2:\n",
      "    input     > [2 2 3 2 3 0 0 0]\n",
      "    predicted > [9 1 1 2 1 2 8 4 4]\n",
      "1000th batch\n",
      "  minibatch loss: 0.051749933511\n",
      "  sample 1:\n",
      "    input     > [3 2 2 3 3 3 0 0]\n",
      "    predicted > [3 2 2 3 3 3 1 0 0]\n",
      "  sample 2:\n",
      "    input     > [3 3 2 2 2 2 2 0]\n",
      "    predicted > [3 3 2 2 2 2 2 1 0]\n",
      "2000th batch\n",
      "  minibatch loss: 0.0194937121123\n",
      "  sample 1:\n",
      "    input     > [2 3 2 2 3 3 3 0]\n",
      "    predicted > [2 3 2 2 3 3 3 1 0]\n",
      "  sample 2:\n",
      "    input     > [2 3 3 3 0 0 0 0]\n",
      "    predicted > [2 3 3 3 1 0 0 0 0]\n",
      "3000th batch\n",
      "  minibatch loss: 0.0073439697735\n",
      "  sample 1:\n",
      "    input     > [2 3 2 3 0 0 0 0]\n",
      "    predicted > [2 3 2 3 1 0 0 0 0]\n",
      "  sample 2:\n",
      "    input     > [2 2 2 3 3 2 2 2]\n",
      "    predicted > [2 2 2 3 3 2 2 2 1]\n"
     ]
    }
   ],
   "source": [
    "for batch in range(3001):\n",
    "    feeddict = next_feed()\n",
    "    _, l = sess.run([train_op, loss], feeddict)\n",
    "    loss_track.append(l)\n",
    "\n",
    "    if batch == 0 or batch % 1000 == 0:\n",
    "        print('{}th batch'.format(batch))\n",
    "        print('  minibatch loss: {}'.format(sess.run(loss, feeddict)))\n",
    "        predict_ = sess.run(decoder_prediction, feeddict) # feeddict内含decoder_input，为什么可以直接用来预测？？\n",
    "        for i, (inp, pred) in enumerate(zip(feeddict[encoder_inputs].T, predict_.T)):\n",
    "            print('  sample {}:'.format(i + 1))\n",
    "            print('    input     > {}'.format(inp))\n",
    "            print('    predicted > {}'.format(pred))\n",
    "            if i >= 1:\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 0.0074 after 300100 examples (batch_size=100)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f8cdc015f90>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(loss_track)\n",
    "print('loss {:.4f} after {} examples (batch_size={})'.format(loss_track[-1], len(loss_track)*batch_size, batch_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Limitations of the model\n",
    "\n",
    "We have no control over transitions of `tf.nn.dynamic_rnn`, it is unrolled in a single sweep. Some of the things that are not possible without such control:\n",
    "\n",
    "- We can't feed previously generated tokens without falling back to Python loops. This means *we cannot make efficient inference with dynamic_rnn decoder*!\n",
    "\n",
    "- We can't use attention, because attention conditions decoder inputs on its previous state\n",
    "\n",
    "Solution would be to use `tf.nn.raw_rnn` instead of `tf.nn.dynamic_rnn` for decoder, as we will do in tutorial #2. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fun things to try (aka Exercises)\n",
    "\n",
    "- In `copy_task` increasing `max_sequence_size` and `vocab_upper`. Observe slower learning and general performance degradation.\n",
    "\n",
    "- For `decoder_inputs`, instead of shifted target sequence `[<EOS> W X Y Z]`, try feeding `[<EOS> <PAD> <PAD> <PAD>]`, like we've done when we tested forward pass. Does it break things? Or slows learning?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Something is definitely getting learned."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kernelForTF",
   "language": "python",
   "name": "kernelfortf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
