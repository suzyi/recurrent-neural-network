{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attention-based Seq2seq Model for Eng2Jap Translation\n",
    "Guorui Shen, guorui233@outlook.com\n",
    "\n",
    "Jun 28, 2019.\n",
    "\n",
    "This notebook is modified from \n",
    "+ https://github.com/wanasit/katakana/blob/master/notebooks/Attention-based%20Sequence-to-Sequence%20in%20Keras.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/io/Desktop\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from time import time\n",
    "from keras.layers import Input, Embedding, LSTM, TimeDistributed, Dense\n",
    "from keras.models import Model, load_model\n",
    "\n",
    "# To import 'katakana' from relative path\n",
    "sys.path.append(os.path.abspath(os.path.join('..')))\n",
    "\n",
    "INPUT_LENGTH = 20\n",
    "OUTPUT_LENGTH = 20\n",
    "time_begin = time()\n",
    "print(sys.path[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0    Unschooling\n",
      "1       Lovosice\n",
      "Name: 0, dtype: object, 0    アンスクーリング\n",
      "1      ロヴォシツェ\n",
      "Name: 1, dtype: object)\n",
      "------------------------------------------------------------\n",
      "(11206      Dorogobuzh\n",
      "80376    Gail Hopkins\n",
      "Name: 0, dtype: object, 11206       ドロゴブージ\n",
      "80376    ゲイル・ホプキンス\n",
      "Name: 1, dtype: object)\n",
      "------------------------------------------------------------\n",
      "([u'dorogobuzh', u'gail hopkins'], [u'\\u30c9\\u30ed\\u30b4\\u30d6\\u30fc\\u30b8', u'\\u30b2\\u30a4\\u30eb\\u30fb\\u30db\\u30d7\\u30ad\\u30f3\\u30b9'])\n",
      "------------------------------------------------------------\n",
      "training size is 64356\n",
      "validation size is 10726\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('eng2jap.csv', header=None)\n",
    "print(data[0][:2], data[1][:2])\n",
    "print('------------------------------------------------------------')\n",
    "data = data.sample(frac=1, random_state=0) # random_state=0 is seed for the random number generator\n",
    "print(data[0][:2], data[1][:2])\n",
    "print('------------------------------------------------------------')\n",
    "\n",
    "# `str.lower()` is to convert a string from uppercase, or even part uppercase to lowercase\n",
    "utf8_eng = [s.decode('utf-8').lower() for s in data[0]]\n",
    "utf8_kat = [s.decode('utf-8') for s in data[1]]\n",
    "print(utf8_eng[:2], utf8_kat[:2])\n",
    "print('------------------------------------------------------------')\n",
    "\n",
    "data_size = len(data)\n",
    "# We will use the first 0-60th %-tile (60% of data for the training\n",
    "training_utf8_eng  = utf8_eng[data_size*0/100:data_size*60/100]\n",
    "training_utf8_kat = utf8_kat[data_size*0/100:data_size*60/100]\n",
    "\n",
    "# We will use the first 60-70th %-tile (10%) of data for the training\n",
    "validation_utf8_eng = utf8_eng[data_size*60/100:data_size*70/100]\n",
    "validation_utf8_kat = utf8_kat[data_size*60/100:data_size*70/100]\n",
    "\n",
    "print('training size is {}'.format(len(training_utf8_eng)))\n",
    "print('validation size is {}'.format(len(validation_utf8_eng)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform data into Numpy arrays\n",
    "\n",
    "We transform the sequences of characters into sequences of integer IDs. This will be done by using pre-written functions in `encoding` module. \n",
    "- First, `encoding.build_characters_encoding` will build encoding/decoding dictionary from the data. \n",
    "- Then, `encoding.transform` will transform the data into numpy array.\n",
    "\n",
    "Check [the previous notebook](./Writing Katakana using Sequence-to-Sequence in Keras) for the details about the transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def char_int_relation(names):\n",
    "    \"\"\"\n",
    "    input:\n",
    "        names: list of strings\n",
    "    return:\n",
    "        char2int\n",
    "        int2char\n",
    "        count\n",
    "    \"\"\"\n",
    "    count = 2\n",
    "    char2int = {}\n",
    "    int2char = {1: 'START'}\n",
    "    for c in set([c for name in names for c in name]):\n",
    "        char2int[c] = count\n",
    "        int2char[count] = c\n",
    "        count += 1\n",
    "    return char2int, int2char, count\n",
    "\n",
    "def transform(char2int, utf8_eng_or_kat, vector_size=20):\n",
    "    \"\"\"\n",
    "    Transform a batch of names into their number representations, \n",
    "    e.g. [John, Jorge] -> [[81, 23, 47, 64, ...], [81, 23, 55, 22, 42, ...]]\n",
    "    \n",
    "    input:\n",
    "        encoding: encoding dict built by char_int_relation()\n",
    "        utf8_eng_or_kat: list of strings\n",
    "        vector_size:\n",
    "    return:\n",
    "    \"\"\"\n",
    "    transformed_data = np.zeros(\n",
    "        shape=(len(utf8_eng_or_kat), vector_size), \n",
    "        dtype='int')\n",
    "    for i in range(len(utf8_eng_or_kat)):\n",
    "        for j in range(min(len(utf8_eng_or_kat[i]), vector_size)):\n",
    "            transformed_data[i][j] = char2int[utf8_eng_or_kat[i][j]]\n",
    "    return transformed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('English character dict size:', 54)\n",
      "('Katakana character dict size:', 89)\n",
      "('training_enc_in', (64356, 20))\n",
      "('encoded_training_out', (64356, 20))\n",
      "('encoded_validation_in', (10726, 20))\n",
      "('encoded_validation_out', (10726, 20))\n"
     ]
    }
   ],
   "source": [
    "engchar2int_dict, int2engchar_dict, eng_char_size = char_int_relation(\n",
    "    utf8_eng)\n",
    "katchar2int_dict, int2katchar_dict, kat_char_size = char_int_relation(utf8_kat)\n",
    "\n",
    "print('English character dict size:', eng_char_size)\n",
    "print('Katakana character dict size:', kat_char_size)\n",
    "\n",
    "training_enc_in = transform(\n",
    "    engchar2int_dict, training_utf8_eng, vector_size=INPUT_LENGTH)\n",
    "encoded_training_out = transform(\n",
    "    katchar2int_dict, training_utf8_kat, vector_size=OUTPUT_LENGTH)\n",
    "\n",
    "print('training_enc_in', training_enc_in.shape)\n",
    "print('encoded_training_out', encoded_training_out.shape)\n",
    "\n",
    "encoded_validation_in = transform(\n",
    "    engchar2int_dict, validation_utf8_eng, vector_size=INPUT_LENGTH)  # INPUT_LENGTH=20\n",
    "encoded_validation_out = transform(\n",
    "    katchar2int_dict, validation_utf8_kat, vector_size=OUTPUT_LENGTH) # OUTPUT_LENGTH=20\n",
    "\n",
    "print('encoded_validation_in', encoded_validation_in.shape)\n",
    "print('encoded_validation_out', encoded_validation_out.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequence-to-Sequence in Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder / Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('enc_in', <tf.Tensor 'embedding_1/embedding_lookup:0' shape=(?, 20, 64) dtype=float32>)\n",
      "('enc_full_state_h LSTM layer', <tf.Tensor 'lstm_1/transpose_2:0' shape=(?, 20, 64) dtype=float32>)\n",
      "('enc_last', <tf.Tensor 'strided_slice:0' shape=(?, 64) dtype=float32>)\n",
      "('dec_full_state_h', <tf.Tensor 'lstm_2/transpose_2:0' shape=(?, 20, 64) dtype=float32>)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "In = Input(shape=(input_length, ))\n",
    "\n",
    "keras.layers.Embedding(input_dim, # Size of the vocabulary\n",
    "    output_dim,\n",
    "    embeddings_initializer='uniform', \n",
    "    embeddings_regularizer=None, \n",
    "    activity_regularizer=None, \n",
    "    embeddings_constraint=None, \n",
    "    mask_zero=False, \n",
    "    input_length=input_length)(In)\n",
    "\n",
    "    `mask_zero=True` If this is True then all subsequent layers in the model need to support masking \n",
    "or an exception will be raised. If mask_zero is set to True, as a consequence, \n",
    "index 0 cannot be used in the vocabulary (input_dim should equal size of vocabulary + 1.\n",
    "\n",
    "In: 2D tensor with shape: (batch_size, input_length), here `input_length` is kind of like unrolling timesteps.\n",
    "return: 3D tensor with shape: (batch_size, input_length, output_dim)\n",
    "\"\"\"\n",
    "enc_in_placeholder = Input(shape=(INPUT_LENGTH,))\n",
    "dec_in_placeholder = Input(shape=(OUTPUT_LENGTH,))\n",
    "\n",
    "\n",
    "enc_in = Embedding(input_dim=eng_char_size, \n",
    "                          output_dim=64, \n",
    "                          input_length=INPUT_LENGTH, \n",
    "                          mask_zero=True)(enc_in_placeholder)\n",
    "print('enc_in', enc_in)\n",
    "enc_full_state_h = LSTM(units=64, \n",
    "                            return_sequences=True, # state_final_state_h (False), state_full_state_h (True)\n",
    "                            return_state=False, # (True) state_final_h and state_final_c\n",
    "                            unroll=True)(enc_in)\n",
    "print('enc_full_state_h LSTM layer', enc_full_state_h)\n",
    "\n",
    "enc_last = enc_full_state_h[:,-1,:]\n",
    "print('enc_last', enc_last)\n",
    "\n",
    "dec_in = Embedding(input_dim=kat_char_size, \n",
    "                          output_dim=64, \n",
    "                          input_length=OUTPUT_LENGTH, \n",
    "                          mask_zero=True)(dec_in_placeholder)\n",
    "dec_full_state_h = LSTM(units=64,\n",
    "                       return_sequences=True, \n",
    "                       unroll=True\n",
    "                      )(dec_in, \n",
    "                        initial_state=[enc_last, enc_last])\n",
    "\n",
    "print('dec_full_state_h', dec_full_state_h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attention Mechanism\n",
    "\n",
    "**Reference**\n",
    "+ [Effective Approaches to Attention-based Neural Machine Translation](https://arxiv.org/pdf/1508.04025.pdf)'s \n",
    "**Global Attention** with **Dot**-based scoring function (Section 3, and subsection 3.1).\n",
    "\n",
    "<img src=\"https://suzyi.github.io/images/global-attention.png\" alt=\"rnn unrolling\" width=400px/>\n",
    "where\n",
    "+ $a_t$ is global align weights.\n",
    "+ $\\bar{h}_s$ is encoder (or source) hidden state.\n",
    "+ $h_t$ is decoder (or target) hidden state.\n",
    "+ $\\tilde{h}_t$ is defined $\\tilde{h}_t = \\text{tanh}(W_c[c_t, h_t])$, where $[c_t, h_t]$ is concanate (or hstack) operation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('scores', <tf.Tensor 'dot_1/MatMul:0' shape=(?, 20, 20) dtype=float32>)\n",
      "('global_align_weights', <tf.Tensor 'global_align_weights/truediv:0' shape=(?, 20, 20) dtype=float32>)\n",
      "('context', <tf.Tensor 'dot_2/MatMul:0' shape=(?, 20, 64) dtype=float32>)\n",
      "('dec_combined_context', <tf.Tensor 'concatenate_1/concat:0' shape=(?, 20, 128) dtype=float32>)\n",
      "('output', <tf.Tensor 'time_distributed_1/Reshape_1:0' shape=(?, 20, 64) dtype=float32>)\n",
      "('output', <tf.Tensor 'time_distributed_2/Reshape_1:0' shape=(?, 20, 89) dtype=float32>)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "TimeDistributed: This wrapper applies a layer to every temporal slice of an input.\n",
    "The input should be at least 3D, and the dimension of index 1 will be considered \n",
    "to be the temporal dimension. The input should be of shape (batch_sz, timesteps, input_dim)\n",
    "TimeDistributed(Dense(8), input_shape=(timesteps, input_dim)) will produce (batch_sz, timesteps, 8)\n",
    "\"\"\"\n",
    "\n",
    "from keras.layers import Activation, dot, concatenate\n",
    "\n",
    "# Equation (7) with 'dot' score from Section 3.1 in the paper.\n",
    "# Note that we reuse Softmax-activation layer instead of writing tensor calculation\n",
    "# dot([(?, 20, 64), (?, 20, 64)], axes=[2, 2]) = (?, 20, 20)\n",
    "scores = dot([dec_full_state_h, enc_full_state_h], axes=[2, 2])\n",
    "print('scores', scores)\n",
    "global_align_weights = Activation('softmax', \n",
    "                                  name='global_align_weights')(scores) # element-wise\n",
    "print('global_align_weights', global_align_weights)\n",
    "\n",
    "# dot([(?, 20, 20), (?, 20, 64)], axes=[2, 1]) = (?, 20, 64)\n",
    "context = dot([global_align_weights, enc_full_state_h], axes=[2,1])\n",
    "print('context', context)\n",
    "\n",
    "dec_combined_context = concatenate([context, dec_full_state_h]) # quite resembles np.hstack((a, b))\n",
    "print('dec_combined_context', dec_combined_context)\n",
    "\n",
    "# Has another weight + tanh layer as described in equation (5) of the paper\n",
    "output = TimeDistributed(Dense(units=64, activation=\"tanh\"))(\n",
    "    dec_combined_context)\n",
    "print('output', output)\n",
    "output = TimeDistributed(Dense(\n",
    "    units=kat_char_size, \n",
    "    activation=\"softmax\"))(output)\n",
    "print('output', output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(inputs=[enc_in_placeholder, dec_in_placeholder], \n",
    "              outputs=[output])\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('training_dec_out.shape', (64356, 20, 89))\n"
     ]
    }
   ],
   "source": [
    "training_dec_in = np.ones_like(encoded_training_out) # start=1\n",
    "training_dec_in[:, 1:] = encoded_training_out[:,:-1]\n",
    "\n",
    "# convert `encoded_training_out` into one_hot\n",
    "# kat_char_size=89, shape(encoded_training_out)=(batch_sz, 20)\n",
    "training_dec_out = np.eye(kat_char_size)[\n",
    "    encoded_training_out.astype('int')]\n",
    "print('training_dec_out.shape', training_dec_out.shape)\n",
    "\n",
    "validation_enc_in = encoded_validation_in\n",
    "validation_dec_in = np.ones_like(encoded_validation_out)\n",
    "validation_dec_in[:, 1:] = encoded_validation_out[:,:-1]\n",
    "validation_dec_out = np.eye(kat_char_size)[\n",
    "    encoded_validation_out.astype('int')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 64356 samples, validate on 10726 samples\n",
      "Epoch 1/30\n",
      " - 36s - loss: 3.2154 - val_loss: 2.7856\n",
      "Epoch 2/30\n",
      " - 31s - loss: 2.3634 - val_loss: 1.9352\n",
      "Epoch 3/30\n",
      " - 31s - loss: 1.5141 - val_loss: 1.2080\n",
      "Epoch 4/30\n",
      " - 32s - loss: 1.1104 - val_loss: 1.0416\n",
      "Epoch 5/30\n",
      " - 32s - loss: 0.9863 - val_loss: 0.9453\n",
      "Epoch 6/30\n",
      " - 31s - loss: 0.9125 - val_loss: 0.8905\n",
      "Epoch 7/30\n",
      " - 31s - loss: 0.8602 - val_loss: 0.8595\n",
      "Epoch 8/30\n",
      " - 30s - loss: 0.8213 - val_loss: 0.8211\n",
      "Epoch 9/30\n",
      " - 31s - loss: 0.7919 - val_loss: 0.8021\n",
      "Epoch 10/30\n",
      " - 31s - loss: 0.7684 - val_loss: 0.7876\n",
      "Epoch 11/30\n",
      " - 30s - loss: 0.7489 - val_loss: 0.7690\n",
      "Epoch 12/30\n",
      " - 30s - loss: 0.7320 - val_loss: 0.7572\n",
      "Epoch 13/30\n",
      " - 30s - loss: 0.7182 - val_loss: 0.7456\n",
      "Epoch 14/30\n",
      " - 30s - loss: 0.7057 - val_loss: 0.7362\n",
      "Epoch 15/30\n",
      " - 31s - loss: 0.6944 - val_loss: 0.7334\n",
      "Epoch 16/30\n",
      " - 32s - loss: 0.6849 - val_loss: 0.7208\n",
      "Epoch 17/30\n",
      " - 32s - loss: 0.6753 - val_loss: 0.7191\n",
      "Epoch 18/30\n",
      " - 31s - loss: 0.6674 - val_loss: 0.7127\n",
      "Epoch 19/30\n",
      " - 31s - loss: 0.6596 - val_loss: 0.7111\n",
      "Epoch 20/30\n",
      " - 31s - loss: 0.6532 - val_loss: 0.7048\n",
      "Epoch 21/30\n",
      " - 33s - loss: 0.6464 - val_loss: 0.6991\n",
      "Epoch 22/30\n",
      " - 31s - loss: 0.6403 - val_loss: 0.7021\n",
      "Epoch 23/30\n",
      " - 31s - loss: 0.6351 - val_loss: 0.6990\n",
      "Epoch 24/30\n",
      " - 31s - loss: 0.6298 - val_loss: 0.6947\n",
      "Epoch 25/30\n",
      " - 31s - loss: 0.6248 - val_loss: 0.6910\n",
      "Epoch 26/30\n",
      " - 31s - loss: 0.6203 - val_loss: 0.6888\n",
      "Epoch 27/30\n",
      " - 31s - loss: 0.6164 - val_loss: 0.6905\n",
      "Epoch 28/30\n",
      " - 31s - loss: 0.6122 - val_loss: 0.6896\n",
      "Epoch 29/30\n",
      " - 31s - loss: 0.6080 - val_loss: 0.6840\n",
      "Epoch 30/30\n",
      " - 30s - loss: 0.6048 - val_loss: 0.6841\n",
      "Train on 64356 samples, validate on 10726 samples\n",
      "Epoch 1/1\n"
     ]
    }
   ],
   "source": [
    "if os.path.isfile('model.h5'):\n",
    "    model = load_model('model.h5')\n",
    "else:\n",
    "    model.fit(x=[training_enc_in, training_dec_in], \n",
    "              y=[training_dec_out],\n",
    "          validation_data=([validation_enc_in, \n",
    "                            validation_dec_in],\n",
    "                           [validation_dec_out]),\n",
    "          verbose=2, batch_size=64, epochs=30)\n",
    "\n",
    "model.fit(x=[training_enc_in, training_dec_in], \n",
    "          y=[training_dec_out],\n",
    "      validation_data=([validation_enc_in, \n",
    "                        validation_dec_in],\n",
    "                       [validation_dec_out]),\n",
    "      verbose=2, batch_size=64, epochs=1)\n",
    "model.save('model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(name):\n",
    "    enc_in = transform(engchar2int_dict, [name.lower()], 20)\n",
    "    dec_in = np.zeros(shape=(1, OUTPUT_LENGTH))\n",
    "    dec_in[:, 0] = 1 # start token is 1\n",
    "    for i in range(1, OUTPUT_LENGTH):      \n",
    "        # output is of shape (1, 20)\n",
    "        output = model.predict([enc_in, dec_in]).argmax(\n",
    "            axis=2)\n",
    "        \n",
    "        # dec_in is of shape (1, 20) \n",
    "        dec_in[:,i] = output[:,i]\n",
    "    return dec_in[:,1:]\n",
    "\n",
    "def decode(int2char_dict, sequence):\n",
    "    name = ''\n",
    "    for i in sequence:\n",
    "        if i == 0:\n",
    "            break\n",
    "        name += int2char_dict[i]\n",
    "    return name\n",
    "\n",
    "def eng_to_kat(name):\n",
    "    dec_out = generate(name)\n",
    "    return decode(int2katchar_dict, dec_out[0])\n",
    "\n",
    "\n",
    "common_american_names = ['James', 'John', 'Robert']\n",
    "for name in common_american_names:\n",
    "    print(name, eng_to_kat(name))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(eng_to_kat('Banana'))\n",
    "print(eng_to_kat('Peter Parker'))\n",
    "print(eng_to_kat('Jonny Snow'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize Attention\n",
    "\n",
    "The next step is visualizing the attention values of the medel during the translation. \n",
    "\n",
    "To do that, the first step is to locate \"attention\" layer of the model. The attention layer is the 7th layers of the model (`model.layers[7]`), which is the softmax activation-layer after dot-score. Or we can also simply call `model.get_layer('attention')` as we previously name the layer as \"attention\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = model.layers\n",
    "for l in layers:\n",
    "    print('{}\\t name:{}'.format(str(l), l.name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also need to re-build the model so that it returns the output from the attention layer in addition to the normal output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "align_weights_layer = model.get_layer('global_align_weights') # or model.layers[7]\n",
    "attention_model = Model(inputs=model.inputs, \n",
    "                        outputs=model.outputs + [align_weights_layer.output])\n",
    "\n",
    "print(attention_model)\n",
    "print(attention_model.output_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn\n",
    "\n",
    "seaborn.set(font=['AppleMyungjo'], font_scale=3)\n",
    "\n",
    "def attent_and_generate(name):\n",
    "    enc_in = transform(engchar2int_dict, [name.lower()], 20)\n",
    "    dec_in = np.zeros(shape=(1, OUTPUT_LENGTH))\n",
    "    dec_in[:, 0] = 1 # start token is 1\n",
    "    \n",
    "    for i in range(1, OUTPUT_LENGTH):\n",
    "        output, align_weights = attention_model.predict(\n",
    "            [enc_in, dec_in])\n",
    "        dec_in[:,i] = output.argmax(axis=2)[:,i]\n",
    "        attention_density = align_weights[0]\n",
    "        decoded_out = decode(int2katchar_dict, dec_in[0][1:])\n",
    "        \n",
    "    return attention_density, decoded_out\n",
    "\n",
    "\n",
    "def visualize(name):\n",
    "    attention_density, katakana = attent_and_generate(name)\n",
    "\n",
    "    plt.clf()\n",
    "    plt.figure(figsize=(28,12))\n",
    "    ax = seaborn.heatmap(attention_density[:len(katakana), :len(name)+1],\n",
    "        xticklabels=[w for w in name],\n",
    "        yticklabels=[w for w in katakana])\n",
    "\n",
    "    ax.invert_yaxis()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize('Jonathan Snow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize('Utada Hikaru')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize('Harry Potter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"This piece of code uses {} minutes.\".format((time()-time_begin)/60.))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kernelForTF",
   "language": "python",
   "name": "kernelfortf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
