{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seq2seq for Copying Task\n",
    "Guorui Shen, guorui233@outlook.com\n",
    "\n",
    "Jun 13, 2019.\n",
    "\n",
    "Tutorial for beginer to start building a seq2seq model. Modified from https://github.com/ematvey/tensorflow-seq2seq-tutorials"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task description**. Given a input, which is a list of integer numbers, the seq2seq model is trained to remember and return the list. For example,\n",
    "```\n",
    "raw input        -> padded to have same length -> expected output\n",
    "[3 6 7 3 4 5 3 ] -> [3 6 7 3 4 5 3 0]          -> [3 6 7 3 4 5 3 1 0]\n",
    "[5 3 5 4 7]      -> [5 3 5 4 7 0 0 0]          -> [5 3 5 4 7 1 0 0 0]\n",
    "[2 9 5]          -> [2 9 5 0 0 0 0 0]          -> [2 9 5 1 0 0 0 0 0]\n",
    "```\n",
    "eos = 1, pad = 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import scipy.io as sio\n",
    "\n",
    "tf.reset_default_graph()\n",
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 - Load Data\n",
    "`PAD = 0`, `EOS = 1`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = sio.loadmat('copytask.mat')\n",
    "\n",
    "def next_batch(x, y, z, batch_size):\n",
    "    N = x.shape[1]\n",
    "    batch_indices = np.random.permutation(N)[:batch_size]\n",
    "    return x[:, batch_indices], y[:, batch_indices], z[:, batch_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "batch_encoder_inputs, batch_decoder_inputs, batch_decoder_targets = next_batch(\n",
    "    data['encoder_inputs'], data['decoder_inputs'], data['decoder_targets'], batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_encoder_inputs.shape = (encoder_max_unrolling_time, batch_size) = (8, 100)\n",
      "batch_decoder_inputs.shape = (decoder_max_unrolling_time, batch_size) = (9, 100)\n",
      "batch_decoder_targets.shape = (decoder_max_unrolling_time, batch_size) = (9, 100)\n",
      "--------------example 1---------------\n",
      "encoder_input is  [7 3 5 5 7 5 0 0]\n",
      "decoder_input is  [1 7 3 5 5 7 5 0 0]\n",
      "decoder_target is [7 3 5 5 7 5 1 0 0]\n",
      "--------------example 2---------------\n",
      "encoder_input is  [9 6 2 0 0 0 0 0]\n",
      "decoder_input is  [1 9 6 2 0 0 0 0 0]\n",
      "decoder_target is [9 6 2 1 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "encoder_max_unrolling_time = len(batch_encoder_inputs)\n",
    "decoder_max_unrolling_time = len(batch_decoder_inputs)\n",
    "print(\"batch_encoder_inputs.shape = (encoder_max_unrolling_time, batch_size) = {}\".format(batch_encoder_inputs.shape))\n",
    "print(\"batch_decoder_inputs.shape = (decoder_max_unrolling_time, batch_size) = {}\".format(batch_decoder_inputs.shape))\n",
    "print(\"batch_decoder_targets.shape = (decoder_max_unrolling_time, batch_size) = {}\".format(batch_decoder_targets.shape))\n",
    "for i in range(2):\n",
    "    print('--------------example {}---------------'.format(i+1))\n",
    "    print('encoder_input is  {}'.format(batch_encoder_inputs[:, i]))\n",
    "    print('decoder_input is  {}'.format(batch_decoder_inputs[:, i]))\n",
    "    print('decoder_target is {}'.format(batch_decoder_targets[:, i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # deletable\n",
    "# encoder_inputs_embedded = tf.nn.embedding_lookup(embeddings, batch_encoder_inputs)\n",
    "# print(sess.run(encoder_inputs_embedded).shape)\n",
    "# print(sess.run(encoder_inputs_embedded)[:, :, :5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 - Embeded inputs and outputs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (encoder_max_unrolling_time, batch_size)\n",
    "encoder_inputs = tf.placeholder(shape=(encoder_max_unrolling_time, None), dtype=tf.int32, name='encoder_inputs')\n",
    "\n",
    "# (decoder_max_unrolling_time, batch_size)\n",
    "decoder_inputs = tf.placeholder(shape=(decoder_max_unrolling_time, None), dtype=tf.int32, name='decoder_inputs')\n",
    "\n",
    "# (decoder_target_dim, batch_size)\n",
    "decoder_targets = tf.placeholder(shape=(None, None), dtype=tf.int32, name='decoder_targets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'embeddings' has 10 different rows, the 0th row represents the integer 0, 1st row represents the integer 1, etc.\n",
    "embeddings = tf.Variable(tf.random_uniform([10, 20], -1.0, 1.0), dtype=tf.float32)# (10, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"embedding_lookup:0\", shape=(8, ?, 20), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# (max_time=8, batch_size=100, encoder_input_dim=20)\n",
    "encoder_inputs_embedded = tf.nn.embedding_lookup(embeddings, encoder_inputs)\n",
    "\n",
    "# (max_time=9, batch_size=100, decoder_input_dim=20)\n",
    "decoder_inputs_embedded = tf.nn.embedding_lookup(embeddings, decoder_inputs)\n",
    "print encoder_inputs_embedded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 - Encoder and Decoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder\n",
    "Encoder is designed to have number of input, hidden nodes are 20, 35, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_cell = tf.nn.rnn_cell.LSTMCell(num_units=35)\n",
    "\n",
    "# 'encoder_final_state' is a tensor of shape [batch_size, num_hidden]\n",
    "# 'encoder_outputs' is a tensor of shape [max_unrolling_time, batch_size, num_hidden]\n",
    "# 'encoder_inputs_embedded' is a tensor of shape [max_unrolling_time, batch_size, input_dim]\n",
    "encoder_outputs, encoder_final_state = tf.nn.dynamic_rnn(\n",
    "    cell=encoder_cell, inputs=encoder_inputs_embedded,\n",
    "    dtype=tf.float32, time_major=True)\n",
    "\n",
    "del encoder_outputs\n",
    "\n",
    "'''\n",
    "outputs, state = tf.nn.dynamic_rnn(cell, inputs,　dtype, time_major)\n",
    "\n",
    "If time_major=False(default), both inputs and outputs must be shaped [batch_size, max_time, input_dim],\n",
    "If time_major=True, both inputs and outputs must be shaped [max_time, batch_size, input_dim]\n",
    "    max_time: the number of words in a sentence, max unrolling time.\n",
    "    input_dim:\n",
    "state: the final state.\n",
    "\n",
    "padding: Appending 0‘s to examples to make them equal in length.\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_cell = tf.nn.rnn_cell.LSTMCell(num_units=35)\n",
    "\n",
    "# 'decoder_outputs' is a tensor of shape [max_unrolling_time=9, batch_size=100, num_hidden=20]\n",
    "# 'decoder_inputs_embedded' is a tensor of shape [max_unrolling_time=9, batch_size=100, num_hidden=20]\n",
    "decoder_outputs, decoder_final_state = tf.nn.dynamic_rnn(\n",
    "    cell=decoder_cell, inputs=decoder_inputs_embedded,\n",
    "    initial_state=encoder_final_state,\n",
    "    dtype=tf.float32, time_major=True, scope=\"plain_decoder\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# units: Integer or Long, dimensionality of the output space.\n",
    "decoder_logits = tf.layers.dense(inputs=decoder_outputs, units=10, activation=None)\n",
    "# 'decoder_logits' is a tensor of shape [max_unrolling_time=9, batch_size=100, num_outputs=10]\n",
    "\n",
    "# returns the index with the largest value across axes of a tensor.\n",
    "decoder_prediction = tf.argmax(decoder_logits, axis=2)\n",
    "# 'decoder_prediction' is a tensor of shape [max_unrolling_time=9, batch_size=100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_size=3\n",
      "((9, 3), array([[1, 1, 3],\n",
      "       [0, 2, 0],\n",
      "       [2, 3, 2],\n",
      "       [0, 1, 3],\n",
      "       [3, 3, 2],\n",
      "       [0, 2, 0],\n",
      "       [3, 0, 1],\n",
      "       [2, 1, 3],\n",
      "       [1, 0, 1]]))\n"
     ]
    }
   ],
   "source": [
    "# deletable, understanding tf.argmax\n",
    "a = np.random.normal(-1,1, (9,3,4))\n",
    "# print(a)\n",
    "b = sess.run(tf.argmax(a, axis=2))\n",
    "print(\"batch_size={}\".format(3))\n",
    "print(b.shape, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-13-27db71974d43>:4: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See tf.nn.softmax_cross_entropy_with_logits_v2.\n",
      "\n",
      "2.4611502\n"
     ]
    }
   ],
   "source": [
    "# deletable, Understanding tf.nn.softmax_cross_entropy_with_logits(vector1, vector2)\n",
    "a1, a2 = 6, 5\n",
    "b1, b2 = tf.one_hot(a1, depth=10), tf.one_hot(a2, depth=10)\n",
    "print(sess.run(tf.nn.softmax_cross_entropy_with_logits(labels=b1, logits=b2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'stepwise_cross_entropy' is a tensor of shape [max_unrolling_time=9, batch_size=100, 1]\n",
    "# 'decoder_targets' is a tensor of shape [max_unrolling_time=9, batch_size=100]\n",
    "stepwise_cross_entropy = tf.nn.softmax_cross_entropy_with_logits(\n",
    "    labels=tf.one_hot(decoder_targets, depth=10, dtype=tf.float32),\n",
    "    logits=decoder_logits,\n",
    ")\n",
    "\n",
    "loss = tf.reduce_mean(stepwise_cross_entropy)\n",
    "train_op = tf.train.AdamOptimizer().minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 - Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_track = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------0th batch--------------------\n",
      "  minibatch loss: 2.29209399223\n",
      "sample 1\n",
      "    input     > [8 9 4 4 0 0 0 0]\n",
      "    predicted > [0 0 8 0 0 6 6 6 6]\n",
      "sample 2\n",
      "    input     > [4 8 2 7 6 9 0 0]\n",
      "    predicted > [8 0 0 9 1 1 6 6 6]\n",
      "--------------------1000th batch--------------------\n",
      "  minibatch loss: 0.227524980903\n",
      "sample 1\n",
      "    input     > [9 9 3 9 2 2 9 7]\n",
      "    predicted > [9 9 3 9 2 2 3 6 1]\n",
      "sample 2\n",
      "    input     > [4 3 5 3 0 0 0 0]\n",
      "    predicted > [4 3 5 3 1 0 0 0 0]\n",
      "--------------------2000th batch--------------------\n",
      "  minibatch loss: 0.0570591278374\n",
      "sample 1\n",
      "    input     > [3 2 8 0 0 0 0 0]\n",
      "    predicted > [3 2 8 1 0 0 0 0 0]\n",
      "sample 2\n",
      "    input     > [4 4 6 8 4 8 5 0]\n",
      "    predicted > [4 4 6 8 4 8 5 1 0]\n",
      "--------------------3000th batch--------------------\n",
      "  minibatch loss: 0.0338039398193\n",
      "sample 1\n",
      "    input     > [8 7 7 8 4 8 5 7]\n",
      "    predicted > [8 7 7 8 4 8 5 7 1]\n",
      "sample 2\n",
      "    input     > [3 6 5 2 7 0 0 0]\n",
      "    predicted > [3 6 5 2 7 1 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "for batch in range(3001):\n",
    "    \n",
    "    batch_encoder_inputs, batch_decoder_inputs, batch_decoder_targets = next_batch(\n",
    "        data['encoder_inputs'], data['decoder_inputs'], data['decoder_targets'], batch_size)\n",
    "    \n",
    "    fd = {encoder_inputs: batch_encoder_inputs, \n",
    "                decoder_inputs: batch_decoder_inputs, decoder_targets:batch_decoder_targets}\n",
    "    _, l = sess.run([train_op, loss], feed_dict=fd)\n",
    "    loss_track.append(l)\n",
    "\n",
    "    if batch == 0 or batch % 1000 == 0:\n",
    "        print('--------------------{}th batch--------------------'.format(batch))\n",
    "        print('  minibatch loss: {}'.format(sess.run(loss, feed_dict=fd)))\n",
    "        predict_ = sess.run(decoder_prediction, feed_dict=fd)\n",
    "        # 'fd[encoder_inputs]' is of shape (max_unrolling_time=8, batch_size = 100)\n",
    "        # 'predict_' is of shape (max_unrolling_time=9, batch_size = 100)\n",
    "        for i, (inp, pred) in enumerate(zip(fd[encoder_inputs].T, predict_.T)):\n",
    "            print('sample {}'.format(i + 1))\n",
    "            print('    input     > {}'.format(inp))\n",
    "            print('    predicted > {}'.format(pred))\n",
    "            if i >= 1:\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 0.0403 after 300100 examples (batch_size=100)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f85287af9d0>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(loss_track)\n",
    "print('loss {:.4f} after {} examples (batch_size={})'.format(loss_track[-1], len(loss_track)*batch_size, batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kernelForTF",
   "language": "python",
   "name": "kernelfortf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
